{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set-Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import base packages\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import time\n",
    "import tensorflow as tf\n",
    "\n",
    "# make graphs pretty in ipynb notebooks\n",
    "#%matplotlib inline\n",
    "\n",
    "RANDOM_SEED = 9999\n",
    "\n",
    "# ignore warnings\n",
    "from sklearn.exceptions import DataConversionWarning\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=np.VisibleDeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings('ignore', category=DataConversionWarning)\n",
    "warnings.simplefilter(\"ignore\", category=PendingDeprecationWarning)\n",
    "warnings.simplefilter('ignore', category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>classname</th>\n",
       "      <th>img</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p002</td>\n",
       "      <td>c0</td>\n",
       "      <td>img_44733.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p002</td>\n",
       "      <td>c0</td>\n",
       "      <td>img_72999.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p002</td>\n",
       "      <td>c0</td>\n",
       "      <td>img_25094.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p002</td>\n",
       "      <td>c0</td>\n",
       "      <td>img_69092.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p002</td>\n",
       "      <td>c0</td>\n",
       "      <td>img_92629.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  subject classname            img\n",
       "0    p002        c0  img_44733.jpg\n",
       "1    p002        c0  img_72999.jpg\n",
       "2    p002        c0  img_25094.jpg\n",
       "3    p002        c0  img_69092.jpg\n",
       "4    p002        c0  img_92629.jpg"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first explore the CSV files included with the image directory\n",
    "samples = pd.read_csv('driver_imgs_list.csv')\n",
    "samples.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset Samples: 22424\n",
      "Number of Classes: 10\n"
     ]
    }
   ],
   "source": [
    "# see how many samples are included\n",
    "print('Training Dataset Samples: {}'.format(samples.shape[0]))\n",
    "\n",
    "# see number of classes\n",
    "print('Number of Classes: {}' .format(len((samples['classname']).unique())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set key for classes with the associated distracted behavior\n",
    "classes = {'c0': 'Safe Driving', 'c1': 'Texting - Right', 'c2': 'Talking on the Phone - Right',\n",
    "          'c3': 'Texting - Left', 'c4': 'Talking on the Phone - Left', 'c5': 'Operating The Radio',\n",
    "          'c6': 'Drinking', 'c7': 'Reaching Behind', 'c8': 'Hair and Makeup',\n",
    "          'c9': 'Talkinng to Passenger'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Hair and Makeup                 1911\n",
       "Reaching Behind                 2002\n",
       "Talkinng to Passenger           2129\n",
       "Texting - Right                 2267\n",
       "Operating The Radio             2312\n",
       "Talking on the Phone - Right    2317\n",
       "Drinking                        2325\n",
       "Talking on the Phone - Left     2326\n",
       "Texting - Left                  2346\n",
       "Safe Driving                    2489\n",
       "Name: classname, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see samples per class\n",
    "samples_with_classes = samples.replace({'classname': classes})\n",
    "class_count = samples_with_classes['classname'].value_counts().sort_values(ascending=True)\n",
    "class_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f2d4b2d93c8>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 936x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(13,10))\n",
    "plt.title('Classes by Image Count', size=18)\n",
    "\n",
    "class_count.plot.barh()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# define function to load the data\n",
    "from sklearn.datasets import load_files\n",
    "from keras.utils import np_utils\n",
    "\n",
    "def load_train_data(path):\n",
    "    dataset = load_files(path)\n",
    "    file = np.array(dataset['filenames'])\n",
    "    target = np_utils.to_categorical(np.array(dataset['target']),11)\n",
    "    return file, target\n",
    "\n",
    "#load train, test, and validation datasets from directory using load_data\n",
    "# train_path = os.walk('imgs', 'train')\n",
    "train_path = os.path.join('/mnt/N0360809/imgs', 'train')\n",
    "print(os.path.exists(train_path))\n",
    "train_img, train_target = load_train_data(train_path)\n",
    "\n",
    "# load list of labels (classes)\n",
    "labels = [item[11:13] for item in sorted(glob(\"/mnt/N0360809/imgs/train/*/\"))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train/validation sets using a 80:20 split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, validation, train_targets, validation_targets = train_test_split(\n",
    "    train_img, train_target, test_size=0.2, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total images in Train Set: 17938\n",
      "Total images in Validation Set: 4485\n"
     ]
    }
   ],
   "source": [
    "# view the shape of the sets\n",
    "print('Total images in Train Set: {}' .format(len(train)))\n",
    "print('Total images in Validation Set: {}' .format(len(validation)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function to load images and converts them into 4D tensors\n",
    "import PIL\n",
    "from keras.preprocessing import image\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def load_img_to_tensor(path):\n",
    "    # load RGB image using PIL and resizes to 224x224 (original input to VGG16)\n",
    "    imgs = image.load_img(path, target_size=(224, 224))\n",
    "    # convert image to an array\n",
    "    x = image.img_to_array(imgs)\n",
    "    # convert array into 4D tensor (1, 224, 224, 3) to load into CNN\n",
    " #   return np.expand_dims(x, axis=0)\n",
    "    return np.expand_dims(x, axis=0)\n",
    "\n",
    "# define function to convert array into 4D tensor with shape (samples, 224, 224, 3)\n",
    "def load_arrays_to_tensor(paths):\n",
    "    list_of_tensors = [load_img_to_tensor(path) for path in tqdm(paths)]\n",
    "    return np.vstack(list_of_tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Type: uint8\n",
      "Min: 0.000, Max: 255.000\n"
     ]
    }
   ],
   "source": [
    "# Data Normalization\n",
    "\n",
    "# first verify image pixel range is 0-255\n",
    "from numpy import asarray\n",
    "from PIL import Image as PIL_Image\n",
    "\n",
    "imagepath = os.path.join('/mnt/N0360809/imgs', 'train', 'c0', 'img_34.jpg')\n",
    "test_image = PIL_Image.open(imagepath)\n",
    "pixels = asarray(test_image)\n",
    "\n",
    "print('Data Type: %s' % pixels.dtype)\n",
    "print('Min: %.3f, Max: %.3f' % (pixels.min(), pixels.max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17938/17938 [01:06<00:00, 268.02it/s]\n",
      "100%|██████████| 4485/4485 [00:15<00:00, 283.46it/s]\n",
      "100%|██████████| 15274/15274 [00:54<00:00, 281.14it/s]\n"
     ]
    }
   ],
   "source": [
    "# next normalize data to pixel range of 0-1\n",
    "from PIL import ImageFile    \n",
    "\n",
    "train_tensor = load_arrays_to_tensor(train).astype('float32')/255 \n",
    "valid_tensor = load_arrays_to_tensor(validation).astype('float32')/255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Set-Up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model: LeNet-5 Network (from scratch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will train a the data based on Yann Lecun's LeNet-5 model that was originally used to identify handwritten digits for zipcode recognition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Conv2D, MaxPool2D, AveragePooling2D\n",
    "from keras.layers import Flatten, Dense\n",
    "from keras.models import Sequential\n",
    "def create_lenet5():\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(filters=6, kernel_size=(3, 3), activation='relu', input_shape=(224,224,3)))\n",
    "    model.add(AveragePooling2D())\n",
    "\n",
    "    model.add(Conv2D(filters=16, kernel_size=(3, 3), activation='relu'))\n",
    "    model.add(AveragePooling2D())\n",
    "\n",
    "    model.add(Flatten())\n",
    "\n",
    "    model.add(Dense(units=120, activation='relu'))\n",
    "\n",
    "    model.add(Dense(units=84, activation='relu'))\n",
    "\n",
    "    model.add(Dense(units=11, activation = 'softmax'))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------Summary of LeNet-5 Architecture:----------\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_29 (Conv2D)           (None, 222, 222, 6)       168       \n",
      "_________________________________________________________________\n",
      "average_pooling2d_3 (Average (None, 111, 111, 6)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_30 (Conv2D)           (None, 109, 109, 16)      880       \n",
      "_________________________________________________________________\n",
      "average_pooling2d_4 (Average (None, 54, 54, 16)        0         \n",
      "_________________________________________________________________\n",
      "flatten_38 (Flatten)         (None, 46656)             0         \n",
      "_________________________________________________________________\n",
      "dense_124 (Dense)            (None, 120)               5598840   \n",
      "_________________________________________________________________\n",
      "dense_125 (Dense)            (None, 84)                10164     \n",
      "_________________________________________________________________\n",
      "dense_126 (Dense)            (None, 11)                935       \n",
      "=================================================================\n",
      "Total params: 5,610,987\n",
      "Trainable params: 5,610,987\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# view LeNet-5 architecture summary\n",
    "lenet5 = create_lenet5()\n",
    "print(\"----------Summary of LeNet-5 Architecture:----------\")\n",
    "lenet5.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "# compile the model using adam's and categorical crossentropy\n",
    "# use accuracy as the metric to measure model performance\n",
    "adam = optimizers.adam(lr=0.0001)\n",
    "\n",
    "lenet5.compile(loss='categorical_crossentropy',optimizer=adam,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train LeNet-5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now train the model using early stopping, where the model will stop training after the model stops improving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17938 samples, validate on 4485 samples\n",
      "Epoch 1/20\n",
      "17938/17938 [==============================] - 58s 3ms/step - loss: 0.0513 - accuracy: 0.9866 - val_loss: 0.0474 - val_accuracy: 0.9895\n",
      "Epoch 2/20\n",
      "17938/17938 [==============================] - 59s 3ms/step - loss: 0.0209 - accuracy: 0.9950 - val_loss: 0.0337 - val_accuracy: 0.9931\n",
      "Epoch 3/20\n",
      "17938/17938 [==============================] - 58s 3ms/step - loss: 0.0073 - accuracy: 0.9987 - val_loss: 0.0400 - val_accuracy: 0.9904\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "callback = [EarlyStopping(monitor='val_loss', min_delta=0, \n",
    "                         patience=0, verbose=0, mode='auto', \n",
    "                         baseline=None, restore_best_weights=False)]\n",
    "\n",
    "#define the number of epochs and batch size\n",
    "epochs = 20\n",
    "batch = 64\n",
    "\n",
    "#initialize timer\n",
    "start_time1 = time.clock()\n",
    "\n",
    "#fit the model\n",
    "lenet5.fit(train_tensor, train_targets, \n",
    "          validation_data=(valid_tensor, validation_targets),\n",
    "          epochs=epochs, batch_size=batch, callbacks=callback, verbose=1)\n",
    "\n",
    "#end timer\n",
    "end_time1 = time.clock()\n",
    "\n",
    "#save time\n",
    "lenet5_time = end_time1 - start_time1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LeNet5 training took: 4240.348712000065 seconds\n"
     ]
    }
   ],
   "source": [
    "print(\"LeNet5 training took: {} seconds\".format(lenet5_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17938/17938 [==============================] - 17s 959us/step\n"
     ]
    }
   ],
   "source": [
    "scores = lenet5.evaluate(train_tensor, train_targets, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LeNet-5 Model accuracy: 99.8%\n"
     ]
    }
   ],
   "source": [
    "print('LeNet-5 Model {}: {}%'.format(lenet5.metrics_names[1], round(scores[1]*100,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer Learning: VGG16 Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will train the data based on the original VGG16 architecture implemented by Karen Simonyan and Andrew Zisserman where they investigated CNN performance with large-scale image recognition settings. (view [paper](https://arxiv.org/pdf/1409.1556.pdf) here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_21 (InputLayer)        (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.vgg16 import VGG16\n",
    "# load VGG16 without the top layers\n",
    "vgg16 = VGG16(weights = \"imagenet\", include_top = False, input_shape = (224, 224, 3))\n",
    "\n",
    "# summarize the model\n",
    "vgg16.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model    \n",
    "#Adding custom layers \n",
    "x = vgg16.output\n",
    "x = Flatten()(x)\n",
    "x = Dense(4096, activation=\"relu\")(x)\n",
    "x = Dense(4096, activation=\"relu\")(x)\n",
    "predictions = Dense(11, activation=\"softmax\")(x)\n",
    "\n",
    "vgg16_final = Model(inputs= vgg16.input, outputs= predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze first 15 layers to not be trained\n",
    "for layer in vgg16_final.layers[:15]:\n",
    "    layer.trainable=False\n",
    "for layer in vgg16_final.layers[15:]:\n",
    "    layer.trainable=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 input_21 False\n",
      "1 block1_conv1 False\n",
      "2 block1_conv2 False\n",
      "3 block1_pool False\n",
      "4 block2_conv1 False\n",
      "5 block2_conv2 False\n",
      "6 block2_pool False\n",
      "7 block3_conv1 False\n",
      "8 block3_conv2 False\n",
      "9 block3_conv3 False\n",
      "10 block3_pool False\n",
      "11 block4_conv1 False\n",
      "12 block4_conv2 False\n",
      "13 block4_conv3 False\n",
      "14 block4_pool False\n",
      "15 block5_conv1 True\n",
      "16 block5_conv2 True\n",
      "17 block5_conv3 True\n",
      "18 block5_pool True\n",
      "19 flatten_31 True\n",
      "20 dense_106 True\n",
      "21 dense_107 True\n",
      "22 dense_108 True\n"
     ]
    }
   ],
   "source": [
    "#List out all of the layers in the final model\n",
    "for i,layer in enumerate(vgg16_final.layers):\n",
    "    print(i,layer.name, layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "# compile the model using adam's and categorical crossentropy\n",
    "# use accuracy as the metric to measure model performance\n",
    "adam = optimizers.adam(lr=0.0001)\n",
    "\n",
    "vgg16_final.compile(loss='categorical_crossentropy',optimizer=adam,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train VGG16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now train the model using early stopping, where the model will stop training after the model stops improving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17938 samples, validate on 4485 samples\n",
      "Epoch 1/20\n",
      "17938/17938 [==============================] - 551s 31ms/step - loss: 0.4759 - accuracy: 0.8414 - val_loss: 0.0670 - val_accuracy: 0.9837\n",
      "Epoch 2/20\n",
      "17938/17938 [==============================] - 550s 31ms/step - loss: 0.0374 - accuracy: 0.9891 - val_loss: 0.0532 - val_accuracy: 0.9851\n",
      "Epoch 3/20\n",
      "17938/17938 [==============================] - 550s 31ms/step - loss: 0.0173 - accuracy: 0.9952 - val_loss: 0.0395 - val_accuracy: 0.9902\n",
      "Epoch 4/20\n",
      "17938/17938 [==============================] - 549s 31ms/step - loss: 0.0166 - accuracy: 0.9951 - val_loss: 0.0324 - val_accuracy: 0.9918\n",
      "Epoch 5/20\n",
      "17938/17938 [==============================] - 554s 31ms/step - loss: 0.0177 - accuracy: 0.9945 - val_loss: 0.0392 - val_accuracy: 0.9895\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "callback = [EarlyStopping(monitor='val_loss', min_delta=0, \n",
    "                         patience=0, verbose=0, mode='auto', \n",
    "                         baseline=None, restore_best_weights=False)]\n",
    "\n",
    "#define the number of epochs and batch size\n",
    "epochs = 20\n",
    "batch = 64\n",
    "\n",
    "# initialize timer\n",
    "start_time2 = time.clock()\n",
    "\n",
    "#fit the model\n",
    "vgg16_final.fit(train_tensor, train_targets, \n",
    "          validation_data=(valid_tensor, validation_targets),\n",
    "          epochs=epochs, batch_size=batch, callbacks=callback, verbose=1)\n",
    "\n",
    "#end timer\n",
    "end_time2 = time.clock()\n",
    "\n",
    "#save time\n",
    "vgg16_time = end_time2 - start_time2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG16 training took: 162585.23917699995 seconds\n"
     ]
    }
   ],
   "source": [
    "print(\"VGG16 training took: {} seconds\".format(vgg16_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17938/17938 [==============================] - 284s 16ms/step\n",
      "VGG16 Model accuracy: 99.62%\n"
     ]
    }
   ],
   "source": [
    "scores = vgg16_final.evaluate(train_tensor, train_targets, verbose=1)\n",
    "print('VGG16 Model {}: {}%'.format(vgg16_final.metrics_names[1], round(scores[1]*100,2)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
